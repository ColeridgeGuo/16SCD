{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier as XGB\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.12_62.csv',\n",
       " '0.14_33.csv',\n",
       " '0.16_22.csv',\n",
       " '0.18_12.csv',\n",
       " '0.20_8.csv',\n",
       " '0.22_3.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "csv_list = os.listdir(\"..\\\\data\\\\genus.reabund_feature_selected\")  # list of files\n",
    "pattern = re.compile(r'(0\\.\\d{2}_\\d+\\.csv)')  # check format of filename\n",
    "csv_list = [pattern.match(x).group(0) for x in csv_list] # leave only the needed files\n",
    "csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_feat_select(clf, param_grid, kfold_num=4, grid_search_cv=4):\n",
    "    models = defaultdict(list)\n",
    "    \n",
    "    # k-fold for each dataset with different # of features\n",
    "    for file in csv_list:\n",
    "        df = pd.read_csv(os.path.join(\"..\\\\data\\\\genus.reabund_feature_selected\", file))\n",
    "        df.drop(labels='id', axis=1, inplace=True)\n",
    "        \n",
    "        X = df.iloc[:, :-1]\n",
    "        y = df.iloc[:, -1]\n",
    "        \n",
    "        kf = KFold(n_splits=kfold_num, random_state=42, shuffle=True)  # k-fold cross validation\n",
    "        print(f\"Processing file {file}:\")\n",
    "        \n",
    "        scores = []\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "            # split train-test set\n",
    "            X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            # grid search for the best params\n",
    "            gs = GridSearchCV(clf(),\n",
    "                              param_grid,\n",
    "                              scoring='roc_auc',\n",
    "                              cv=grid_search_cv,\n",
    "                              iid=False,\n",
    "                              n_jobs=-1)\n",
    "        \n",
    "            gs.fit(X_train, y_train.values.ravel())  # train the model\n",
    "            scores.append(gs.score(X_test, y_test))  # save the score of the current fold\n",
    "            print(gs.best_params_)\n",
    "            models[file].append(clf(**gs.best_params_)) # save the model with best params\n",
    "        \n",
    "        # print the score of each fold and the average\n",
    "        print('[', ', '.join([f\"{x:.3f}\" for x in scores]), ']')\n",
    "        score = np.mean(scores)\n",
    "        print(f\"The average score is {score:.3f}\")\n",
    "        print()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 0.12_62.csv:\n",
      "{'learning_rate': 0.2, 'n_estimators': 2}\n",
      "{'learning_rate': 0.1, 'n_estimators': 10}\n",
      "{'learning_rate': 0.3, 'n_estimators': 30}\n",
      "{'learning_rate': 0.2, 'n_estimators': 30}\n",
      "[ 0.652, 0.649, 0.623, 0.610 ]\n",
      "The average score is 0.634\n",
      "\n",
      "Processing file 0.14_33.csv:\n",
      "{'learning_rate': 0.1, 'n_estimators': 2}\n",
      "{'learning_rate': 0.01, 'n_estimators': 50}\n",
      "{'learning_rate': 0.2, 'n_estimators': 2}\n",
      "{'learning_rate': 0.3, 'n_estimators': 5}\n",
      "[ 0.645, 0.532, 0.514, 0.647 ]\n",
      "The average score is 0.585\n",
      "\n",
      "Processing file 0.16_22.csv:\n",
      "{'learning_rate': 0.01, 'n_estimators': 20}\n",
      "{'learning_rate': 0.2, 'n_estimators': 50}\n",
      "{'learning_rate': 0.2, 'n_estimators': 10}\n",
      "{'learning_rate': 0.01, 'n_estimators': 50}\n",
      "[ 0.771, 0.463, 0.643, 0.816 ]\n",
      "The average score is 0.673\n",
      "\n",
      "Processing file 0.18_12.csv:\n",
      "{'learning_rate': 0.01, 'n_estimators': 5}\n",
      "{'learning_rate': 0.3, 'n_estimators': 50}\n",
      "{'learning_rate': 0.3, 'n_estimators': 5}\n",
      "{'learning_rate': 0.01, 'n_estimators': 50}\n",
      "[ 0.703, 0.433, 0.655, 0.794 ]\n",
      "The average score is 0.646\n",
      "\n",
      "Processing file 0.20_8.csv:\n",
      "{'learning_rate': 0.01, 'n_estimators': 5}\n",
      "{'learning_rate': 0.05, 'n_estimators': 10}\n",
      "{'learning_rate': 0.05, 'n_estimators': 2}\n",
      "{'learning_rate': 0.2, 'n_estimators': 2}\n",
      "[ 0.722, 0.714, 0.661, 0.823 ]\n",
      "The average score is 0.730\n",
      "\n",
      "Processing file 0.22_3.csv:\n",
      "{'learning_rate': 0.05, 'n_estimators': 20}\n",
      "{'learning_rate': 0.2, 'n_estimators': 5}\n",
      "{'learning_rate': 0.01, 'n_estimators': 2}\n",
      "{'learning_rate': 0.3, 'n_estimators': 30}\n",
      "[ 0.680, 0.571, 0.597, 0.792 ]\n",
      "The average score is 0.660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# params to search\n",
    "xgb_params = {'n_estimators': (2, 5, 10, 20, 30, 50),\n",
    "                  'learning_rate': (.01, .05, .1, .2, .3)}\n",
    "xgb_models = kfold_feat_select(XGB, xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 0.12_62.csv:\n",
      "{'learning_rate': 0.05, 'n_estimators': 30}\n",
      "{'learning_rate': 0.1, 'n_estimators': 30}\n",
      "{'learning_rate': 0.01, 'n_estimators': 20}\n",
      "{'learning_rate': 0.2, 'n_estimators': 20}\n",
      "[ 0.744, 0.565, 0.563, 0.571 ]\n",
      "The average score is 0.611\n",
      "\n",
      "Processing file 0.14_33.csv:\n",
      "{'learning_rate': 0.01, 'n_estimators': 2}\n",
      "{'learning_rate': 0.1, 'n_estimators': 20}\n",
      "{'learning_rate': 0.01, 'n_estimators': 2}\n",
      "{'learning_rate': 0.2, 'n_estimators': 20}\n",
      "[ 0.671, 0.485, 0.623, 0.543 ]\n",
      "The average score is 0.581\n",
      "\n",
      "Processing file 0.16_22.csv:\n",
      "{'learning_rate': 0.01, 'n_estimators': 2}\n",
      "{'learning_rate': 0.3, 'n_estimators': 50}\n",
      "{'learning_rate': 0.1, 'n_estimators': 50}\n",
      "{'learning_rate': 0.01, 'n_estimators': 20}\n",
      "[ 0.671, 0.613, 0.637, 0.764 ]\n",
      "The average score is 0.671\n",
      "\n",
      "Processing file 0.18_12.csv:\n",
      "{'learning_rate': 0.01, 'n_estimators': 2}\n",
      "{'learning_rate': 0.05, 'n_estimators': 50}\n",
      "{'learning_rate': 0.01, 'n_estimators': 2}\n",
      "{'learning_rate': 0.05, 'n_estimators': 30}\n",
      "[ 0.671, 0.634, 0.623, 0.760 ]\n",
      "The average score is 0.672\n",
      "\n",
      "Processing file 0.20_8.csv:\n",
      "{'learning_rate': 0.01, 'n_estimators': 2}\n",
      "{'learning_rate': 0.1, 'n_estimators': 10}\n",
      "{'learning_rate': 0.05, 'n_estimators': 10}\n",
      "{'learning_rate': 0.3, 'n_estimators': 20}\n",
      "[ 0.671, 0.760, 0.623, 0.658 ]\n",
      "The average score is 0.678\n",
      "\n",
      "Processing file 0.22_3.csv:\n",
      "{'learning_rate': 0.01, 'n_estimators': 2}\n",
      "{'learning_rate': 0.1, 'n_estimators': 50}\n",
      "{'learning_rate': 0.01, 'n_estimators': 30}\n",
      "{'learning_rate': 0.3, 'n_estimators': 2}\n",
      "[ 0.671, 0.658, 0.623, 0.764 ]\n",
      "The average score is 0.679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# params to search\n",
    "ab_params = {'n_estimators': (2, 5, 10, 20, 30, 50),\n",
    "                  'learning_rate': (.01, .05, .1, .2, .3)}\n",
    "ab_models = kfold_feat_select(ABC, ab_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 0.12_62.csv:\n",
      "{'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 10}\n",
      "{'min_samples_leaf': 2, 'min_samples_split': 20, 'n_estimators': 20}\n",
      "{'min_samples_leaf': 4, 'min_samples_split': 20, 'n_estimators': 10}\n",
      "{'min_samples_leaf': 2, 'min_samples_split': 20, 'n_estimators': 50}\n",
      "[ 0.820, 0.610, 0.627, 0.848 ]\n",
      "The average score is 0.726\n",
      "\n",
      "Processing file 0.14_33.csv:\n",
      "{'min_samples_leaf': 6, 'min_samples_split': 24, 'n_estimators': 30}\n",
      "{'min_samples_leaf': 2, 'min_samples_split': 24, 'n_estimators': 10}\n",
      "{'min_samples_leaf': 6, 'min_samples_split': 32, 'n_estimators': 30}\n",
      "{'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 5}\n",
      "[ 0.805, 0.470, 0.694, 0.823 ]\n",
      "The average score is 0.698\n",
      "\n",
      "Processing file 0.16_22.csv:\n",
      "{'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 5}\n",
      "{'min_samples_leaf': 6, 'min_samples_split': 16, 'n_estimators': 10}\n",
      "{'min_samples_leaf': 8, 'min_samples_split': 24, 'n_estimators': 5}\n",
      "{'min_samples_leaf': 4, 'min_samples_split': 20, 'n_estimators': 5}\n",
      "[ 0.782, 0.589, 0.718, 0.686 ]\n",
      "The average score is 0.694\n",
      "\n",
      "Processing file 0.18_12.csv:\n",
      "{'min_samples_leaf': 8, 'min_samples_split': 48, 'n_estimators': 50}\n",
      "{'min_samples_leaf': 6, 'min_samples_split': 8, 'n_estimators': 5}\n",
      "{'min_samples_leaf': 4, 'min_samples_split': 48, 'n_estimators': 30}\n",
      "{'min_samples_leaf': 2, 'min_samples_split': 32, 'n_estimators': 20}\n",
      "[ 0.643, 0.567, 0.694, 0.736 ]\n",
      "The average score is 0.660\n",
      "\n",
      "Processing file 0.20_8.csv:\n",
      "{'min_samples_leaf': 16, 'min_samples_split': 16, 'n_estimators': 5}\n",
      "{'min_samples_leaf': 6, 'min_samples_split': 16, 'n_estimators': 10}\n",
      "{'min_samples_leaf': 16, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "{'min_samples_leaf': 2, 'min_samples_split': 32, 'n_estimators': 10}\n",
      "[ 0.701, 0.522, 0.623, 0.714 ]\n",
      "The average score is 0.640\n",
      "\n",
      "Processing file 0.22_3.csv:\n",
      "{'min_samples_leaf': 8, 'min_samples_split': 32, 'n_estimators': 30}\n",
      "{'min_samples_leaf': 2, 'min_samples_split': 16, 'n_estimators': 20}\n",
      "{'min_samples_leaf': 16, 'min_samples_split': 20, 'n_estimators': 50}\n",
      "{'min_samples_leaf': 4, 'min_samples_split': 16, 'n_estimators': 5}\n",
      "[ 0.694, 0.660, 0.669, 0.805 ]\n",
      "The average score is 0.707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# params to search\n",
    "rf_params = {'n_estimators': (5, 10, 20, 30, 50, 100),\n",
    "          'min_samples_split': (8, 16, 20, 24, 32, 48),\n",
    "          'min_samples_leaf': (2, 4, 6, 8, 16)}\n",
    "rf_models = kfold_feat_select(RFC, rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
